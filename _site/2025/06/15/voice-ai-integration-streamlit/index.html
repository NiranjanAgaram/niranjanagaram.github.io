<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="I added voice capabilities to my AI applications. Here&#39;s how I integrated speech-to-text and text-to-speech with Streamlit for hands-free AI interactions.">
    <meta name="author" content="Niranjan Agaram">
    <meta name="robots" content="index, follow">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="post">
    <meta property="og:url" content="http://localhost:4009/2025/06/15/voice-ai-integration-streamlit/">
    <meta property="og:title" content="Voice AI Integration: Adding Speech to My AI Applications with Streamlit">
    <meta property="og:description" content="I added voice capabilities to my AI applications. Here&#39;s how I integrated speech-to-text and text-to-speech with Streamlit for hands-free AI interactions.">
    <meta property="og:image" content="http://localhost:4009/assets/images/og-image.svg">
    
    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="http://localhost:4009/2025/06/15/voice-ai-integration-streamlit/">
    <meta property="twitter:title" content="Voice AI Integration: Adding Speech to My AI Applications with Streamlit">
    <meta property="twitter:description" content="I added voice capabilities to my AI applications. Here&#39;s how I integrated speech-to-text and text-to-speech with Streamlit for hands-free AI interactions.">
    <meta property="twitter:image" content="http://localhost:4009/assets/images/og-image.svg">
    
    <!-- Enhanced Structured Data -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Niranjan Agaram",
      "jobTitle": "AI & Data Engineering Consultant",
      "description": "10+ years evolving from data engineering to agentic AI systems across healthcare, retail, marketing, and real estate",
      "url": "http://localhost:4009",
      "sameAs": [
        "https://linkedin.com/in/niranjan-agaram",
        "https://github.com/niranjanagaram"
      ],
      "knowsAbout": [
        "Artificial Intelligence",
        "Data Engineering", 
        "Machine Learning",
        "LangChain",
        "CrewAI",
        "FastAPI",
        "Python",
        "SAS",
        "Multi-Agent Systems"
      ],
      "hasOccupation": {
        "@type": "Occupation",
        "name": "AI Consultant",
        "occupationLocation": {
          "@type": "Country",
          "name": "India"
        }
      }
    }
    </script>
    
    <title>Voice AI Integration: Adding Speech to My AI Applications with Streamlit</title>
    <link rel="canonical" href="http://localhost:4009/2025/06/15/voice-ai-integration-streamlit/">
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    <link rel="stylesheet" href="/assets/css/style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="manifest" href="/manifest.json">
    <meta name="theme-color" content="#3b82f6">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="apple-mobile-web-app-title" content="Niranjan AI">
    <script src="/assets/js/main.js" defer></script>
    <script src="/assets/js/search.js" defer></script>
    <script src="/assets/js/performance.js" defer></script>
    
    <!-- Analytics -->
    
</head>
<body>

    <div class="bg-orb orb-1" aria-hidden="true"></div>
    <div class="bg-orb orb-2" aria-hidden="true"></div>
    
    <!-- Progress Bar -->
    <div class="reading-progress" id="reading-progress" aria-hidden="true"></div>
    
    <header role="banner">
        <div class="container">
            <h1><a href="/" aria-label="Home - Niranjan's AI Insights">Niranjan's AI Insights</a></h1>
            <p>Enterprise AI solutions, agentic systems, and intelligent automation insights from a senior data engineer</p>
            
            <!-- Search -->
            <div class="search-container">
                <input type="search" id="search-input" placeholder="Search posts..." aria-label="Search blog posts">
                <div id="search-results" class="search-results" aria-live="polite"></div>
            </div>
            
            <nav role="navigation" aria-label="Main navigation">
                <div class="nav-links">
                    <a href="/" >Home</a>
                    <a href="/posts" >Posts</a>
                    <a href="/services" >Services</a>
                    <a href="/about" >About</a>
                    <a href="/contact" >Contact</a>
                    <a href="/archive" >Archive</a>
                </div>
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle dark/light mode"></button>
            </nav>
        </div>
    </header>
    
    <main id="main-content" class="container" role="main">
        <article itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    <h1 itemprop="headline">Voice AI Integration: Adding Speech to My AI Applications with Streamlit</h1>
    <div class="post-meta">
      <time datetime="2025-06-15T00:00:00+05:30" itemprop="datePublished">
        June 15, 2025
      </time>
      
        <span itemprop="author" itemscope itemtype="http://schema.org/Person">
          by <span itemprop="name">Niranjan Agaram</span>
        </span>
      
      <span class="reading-time">üìñ 19 min read</span>
    </div>
    
    <div class="tags">
      
        <span class="tag" itemprop="keywords">voice-ai</span>
      
        <span class="tag" itemprop="keywords">streamlit</span>
      
        <span class="tag" itemprop="keywords">speech-to-text</span>
      
        <span class="tag" itemprop="keywords">text-to-speech</span>
      
        <span class="tag" itemprop="keywords">multimodal-ai</span>
      
    </div>
    
  </header>

  <div itemprop="articleBody">
    <h1 id="voice-ai-integration-adding-speech-to-my-ai-applications-with-streamlit">Voice AI Integration: Adding Speech to My AI Applications with Streamlit</h1>

<p>Last month, a nurse approached me with an interesting request: ‚ÄúCan I talk to your AI system while I‚Äôm examining patients? I can‚Äôt always type, but I could really use the diagnostic assistance.‚Äù</p>

<p>This got me thinking about voice interfaces for AI applications. After two weeks of experimentation, I‚Äôve built voice-enabled versions of my RAG system and multi-agent crew. Here‚Äôs what I learned about making AI truly conversational.</p>

<h2 id="why-voice-ai-matters-in-healthcare">Why Voice AI Matters in Healthcare</h2>

<p>In healthcare settings, hands-free interaction isn‚Äôt just convenient‚Äîit‚Äôs often necessary:</p>
<ul>
  <li><strong>Sterile environments</strong>: Can‚Äôt touch keyboards during procedures</li>
  <li><strong>Multitasking</strong>: Examining patients while accessing information</li>
  <li><strong>Accessibility</strong>: Supporting staff with different abilities</li>
  <li><strong>Speed</strong>: Speaking is often faster than typing for complex queries</li>
</ul>

<h2 id="the-technical-challenge">The Technical Challenge</h2>

<p>Building voice AI involves several components:</p>
<ol>
  <li><strong>Speech-to-Text (STT)</strong>: Convert spoken words to text</li>
  <li><strong>Natural Language Processing</strong>: Process the text with AI</li>
  <li><strong>Text-to-Speech (TTS)</strong>: Convert AI responses back to speech</li>
  <li><strong>Real-time Processing</strong>: Handle continuous conversation</li>
  <li><strong>Noise Handling</strong>: Work in noisy hospital environments</li>
</ol>

<h2 id="my-first-attempt-basic-voice-interface">My First Attempt: Basic Voice Interface</h2>

<h3 id="setting-up-speech-recognition">Setting Up Speech Recognition</h3>

<p>I started with Python‚Äôs built-in speech recognition:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">streamlit</span> <span class="k">as</span> <span class="n">st</span>
<span class="kn">import</span> <span class="nn">speech_recognition</span> <span class="k">as</span> <span class="n">sr</span>
<span class="kn">import</span> <span class="nn">pyttsx3</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">import</span> <span class="nn">tempfile</span>

<span class="k">class</span> <span class="nc">VoiceInterface</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">recognizer</span> <span class="o">=</span> <span class="n">sr</span><span class="p">.</span><span class="n">Recognizer</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">microphone</span> <span class="o">=</span> <span class="n">sr</span><span class="p">.</span><span class="n">Microphone</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">tts_engine</span> <span class="o">=</span> <span class="n">pyttsx3</span><span class="p">.</span><span class="n">init</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">listen_for_speech</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="s">"""Capture speech from microphone"""</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="bp">self</span><span class="p">.</span><span class="n">microphone</span> <span class="k">as</span> <span class="n">source</span><span class="p">:</span>
                <span class="c1"># Adjust for ambient noise
</span>                <span class="bp">self</span><span class="p">.</span><span class="n">recognizer</span><span class="p">.</span><span class="n">adjust_for_ambient_noise</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">st</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Listening... Speak now!"</span><span class="p">)</span>
                
                <span class="c1"># Listen for speech
</span>                <span class="n">audio</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">recognizer</span><span class="p">.</span><span class="n">listen</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
                
            <span class="c1"># Convert speech to text
</span>            <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">recognizer</span><span class="p">.</span><span class="n">recognize_google</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">text</span>
            
        <span class="k">except</span> <span class="n">sr</span><span class="p">.</span><span class="n">WaitTimeoutError</span><span class="p">:</span>
            <span class="k">return</span> <span class="s">"No speech detected"</span>
        <span class="k">except</span> <span class="n">sr</span><span class="p">.</span><span class="n">UnknownValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="s">"Could not understand speech"</span>
        <span class="k">except</span> <span class="n">sr</span><span class="p">.</span><span class="n">RequestError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s">"Speech recognition error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s">"</span>
    
    <span class="k">def</span> <span class="nf">speak_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="s">"""Convert text to speech"""</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">tts_engine</span><span class="p">.</span><span class="n">say</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">tts_engine</span><span class="p">.</span><span class="n">runAndWait</span><span class="p">()</span>

<span class="c1"># Streamlit app
</span><span class="n">st</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Voice-Enabled Medical Assistant"</span><span class="p">)</span>

<span class="n">voice_interface</span> <span class="o">=</span> <span class="n">VoiceInterface</span><span class="p">()</span>

<span class="k">if</span> <span class="n">st</span><span class="p">.</span><span class="n">button</span><span class="p">(</span><span class="s">"üé§ Start Voice Query"</span><span class="p">):</span>
    <span class="n">spoken_text</span> <span class="o">=</span> <span class="n">voice_interface</span><span class="p">.</span><span class="n">listen_for_speech</span><span class="p">()</span>
    <span class="n">st</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"You said: </span><span class="si">{</span><span class="n">spoken_text</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">spoken_text</span> <span class="ow">and</span> <span class="s">"error"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">spoken_text</span><span class="p">.</span><span class="n">lower</span><span class="p">():</span>
        <span class="c1"># Process with AI
</span>        <span class="n">response</span> <span class="o">=</span> <span class="n">process_medical_query</span><span class="p">(</span><span class="n">spoken_text</span><span class="p">)</span>
        <span class="n">st</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"AI Response: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        
        <span class="c1"># Speak the response
</span>        <span class="n">voice_interface</span><span class="p">.</span><span class="n">speak_text</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Problems with this approach</strong>:</p>
<ul>
  <li><strong>Blocking interface</strong>: Streamlit froze while listening</li>
  <li><strong>Poor audio quality</strong>: Basic microphone handling</li>
  <li><strong>No real-time feedback</strong>: Users didn‚Äôt know if they were being heard</li>
  <li><strong>Limited TTS options</strong>: Robotic-sounding speech</li>
</ul>

<h2 id="iteration-2-better-audio-handling">Iteration 2: Better Audio Handling</h2>

<h3 id="using-streamlit-audio-components">Using Streamlit Audio Components</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">streamlit</span> <span class="k">as</span> <span class="n">st</span>
<span class="kn">from</span> <span class="nn">streamlit_webrtc</span> <span class="kn">import</span> <span class="n">webrtc_streamer</span><span class="p">,</span> <span class="n">WebRtcMode</span><span class="p">,</span> <span class="n">RTCConfiguration</span>
<span class="kn">import</span> <span class="nn">av</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">whisper</span>

<span class="k">class</span> <span class="nc">AdvancedVoiceInterface</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">whisper_model</span> <span class="o">=</span> <span class="n">whisper</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">"base"</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">audio_buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">16000</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># 10 seconds buffer
</span>        
    <span class="k">def</span> <span class="nf">process_audio_frame</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
        <span class="s">"""Process real-time audio frames"""</span>
        <span class="n">audio_array</span> <span class="o">=</span> <span class="n">frame</span><span class="p">.</span><span class="n">to_ndarray</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">audio_buffer</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">audio_array</span><span class="p">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">frame</span>
    
    <span class="k">def</span> <span class="nf">transcribe_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Transcribe accumulated audio buffer"""</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">audio_buffer</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">16000</span><span class="p">:</span>  <span class="c1"># Need at least 1 second
</span>            <span class="k">return</span> <span class="s">""</span>
            
        <span class="n">audio_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">audio_buffer</span><span class="p">))</span>
        
        <span class="c1"># Normalize audio
</span>        <span class="n">audio_data</span> <span class="o">=</span> <span class="n">audio_data</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">32768.0</span>
        
        <span class="c1"># Transcribe with Whisper
</span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">whisper_model</span><span class="p">.</span><span class="n">transcribe</span><span class="p">(</span><span class="n">audio_data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span><span class="p">[</span><span class="s">"text"</span><span class="p">]</span>

<span class="c1"># Streamlit WebRTC component
</span><span class="n">st</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Real-Time Voice Medical Assistant"</span><span class="p">)</span>

<span class="n">voice_interface</span> <span class="o">=</span> <span class="n">AdvancedVoiceInterface</span><span class="p">()</span>

<span class="c1"># WebRTC audio streaming
</span><span class="n">webrtc_ctx</span> <span class="o">=</span> <span class="n">webrtc_streamer</span><span class="p">(</span>
    <span class="n">key</span><span class="o">=</span><span class="s">"speech-to-text"</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="n">WebRtcMode</span><span class="p">.</span><span class="n">SENDONLY</span><span class="p">,</span>
    <span class="n">audio_processor_factory</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">voice_interface</span><span class="p">,</span>
    <span class="n">rtc_configuration</span><span class="o">=</span><span class="n">RTCConfiguration</span><span class="p">(</span>
        <span class="p">{</span><span class="s">"iceServers"</span><span class="p">:</span> <span class="p">[{</span><span class="s">"urls"</span><span class="p">:</span> <span class="p">[</span><span class="s">"stun:stun.l.google.com:19302"</span><span class="p">]}]}</span>
    <span class="p">),</span>
    <span class="n">media_stream_constraints</span><span class="o">=</span><span class="p">{</span><span class="s">"video"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">"audio"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span>
<span class="p">)</span>

<span class="c1"># Real-time transcription display
</span><span class="k">if</span> <span class="n">webrtc_ctx</span><span class="p">.</span><span class="n">audio_processor</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">st</span><span class="p">.</span><span class="n">button</span><span class="p">(</span><span class="s">"Get Current Transcription"</span><span class="p">):</span>
        <span class="n">transcription</span> <span class="o">=</span> <span class="n">voice_interface</span><span class="p">.</span><span class="n">transcribe_buffer</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">transcription</span><span class="p">:</span>
            <span class="n">st</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"Transcribed: </span><span class="si">{</span><span class="n">transcription</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            
            <span class="c1"># Process with medical AI
</span>            <span class="n">response</span> <span class="o">=</span> <span class="n">process_medical_query</span><span class="p">(</span><span class="n">transcription</span><span class="p">)</span>
            <span class="n">st</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"Medical AI: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p>This was better, but still had issues with real-time processing and user experience.</p>

<h2 id="iteration-3-production-ready-voice-interface">Iteration 3: Production-Ready Voice Interface</h2>

<h3 id="using-openai-whisper-and-elevenlabs">Using OpenAI Whisper and ElevenLabs</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">streamlit</span> <span class="k">as</span> <span class="n">st</span>
<span class="kn">import</span> <span class="nn">openai</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">base64</span>
<span class="kn">from</span> <span class="nn">audio_recorder_streamlit</span> <span class="kn">import</span> <span class="n">audio_recorder</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">class</span> <span class="nc">ProductionVoiceInterface</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">openai_client</span> <span class="o">=</span> <span class="n">openai</span><span class="p">.</span><span class="n">OpenAI</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">elevenlabs_api_key</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">getenv</span><span class="p">(</span><span class="s">"ELEVENLABS_API_KEY"</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">voice_id</span> <span class="o">=</span> <span class="s">"21m00Tcm4TlvDq8ikWAM"</span>  <span class="c1"># Professional female voice
</span>        
    <span class="k">def</span> <span class="nf">transcribe_audio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_bytes</span><span class="p">):</span>
        <span class="s">"""Transcribe audio using OpenAI Whisper"""</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Save audio to temporary file
</span>            <span class="k">with</span> <span class="n">tempfile</span><span class="p">.</span><span class="n">NamedTemporaryFile</span><span class="p">(</span><span class="n">delete</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s">".wav"</span><span class="p">)</span> <span class="k">as</span> <span class="n">tmp_file</span><span class="p">:</span>
                <span class="n">tmp_file</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">)</span>
                <span class="n">tmp_file_path</span> <span class="o">=</span> <span class="n">tmp_file</span><span class="p">.</span><span class="n">name</span>
            
            <span class="c1"># Transcribe with OpenAI Whisper
</span>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">tmp_file_path</span><span class="p">,</span> <span class="s">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">audio_file</span><span class="p">:</span>
                <span class="n">transcript</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">openai_client</span><span class="p">.</span><span class="n">audio</span><span class="p">.</span><span class="n">transcriptions</span><span class="p">.</span><span class="n">create</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="s">"whisper-1"</span><span class="p">,</span>
                    <span class="nb">file</span><span class="o">=</span><span class="n">audio_file</span><span class="p">,</span>
                    <span class="n">response_format</span><span class="o">=</span><span class="s">"text"</span>
                <span class="p">)</span>
            
            <span class="c1"># Clean up
</span>            <span class="n">os</span><span class="p">.</span><span class="n">unlink</span><span class="p">(</span><span class="n">tmp_file_path</span><span class="p">)</span>
            
            <span class="k">return</span> <span class="n">transcript</span>
            
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">st</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"Transcription error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">None</span>
    
    <span class="k">def</span> <span class="nf">generate_speech</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="s">"""Generate speech using ElevenLabs"""</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"https://api.elevenlabs.io/v1/text-to-speech/</span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">voice_id</span><span class="si">}</span><span class="s">"</span>
            
            <span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s">"Accept"</span><span class="p">:</span> <span class="s">"audio/mpeg"</span><span class="p">,</span>
                <span class="s">"Content-Type"</span><span class="p">:</span> <span class="s">"application/json"</span><span class="p">,</span>
                <span class="s">"xi-api-key"</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">elevenlabs_api_key</span>
            <span class="p">}</span>
            
            <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s">"text"</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
                <span class="s">"model_id"</span><span class="p">:</span> <span class="s">"eleven_monolingual_v1"</span><span class="p">,</span>
                <span class="s">"voice_settings"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s">"stability"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
                    <span class="s">"similarity_boost"</span><span class="p">:</span> <span class="mf">0.5</span>
                <span class="p">}</span>
            <span class="p">}</span>
            
            <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">response</span><span class="p">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">response</span><span class="p">.</span><span class="n">content</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">st</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"TTS error: </span><span class="si">{</span><span class="n">response</span><span class="p">.</span><span class="n">status_code</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">None</span>
                
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">st</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"Speech generation error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">None</span>

<span class="c1"># Medical AI Integration
</span><span class="k">class</span> <span class="nc">VoiceMedicalAssistant</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">voice_interface</span> <span class="o">=</span> <span class="n">ProductionVoiceInterface</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conversation_history</span> <span class="o">=</span> <span class="p">[]</span>
        
    <span class="k">def</span> <span class="nf">process_voice_query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_bytes</span><span class="p">):</span>
        <span class="s">"""Process complete voice interaction"""</span>
        <span class="c1"># Transcribe speech
</span>        <span class="n">transcription</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">voice_interface</span><span class="p">.</span><span class="n">transcribe_audio</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">transcription</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
        
        <span class="c1"># Add to conversation history
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">conversation_history</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"user"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="n">transcription</span><span class="p">})</span>
        
        <span class="c1"># Process with medical AI (using your existing RAG system)
</span>        <span class="n">ai_response</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_medical_response</span><span class="p">(</span><span class="n">transcription</span><span class="p">)</span>
        
        <span class="c1"># Add AI response to history
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">conversation_history</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"assistant"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="n">ai_response</span><span class="p">})</span>
        
        <span class="c1"># Generate speech response
</span>        <span class="n">speech_audio</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">voice_interface</span><span class="p">.</span><span class="n">generate_speech</span><span class="p">(</span><span class="n">ai_response</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">transcription</span><span class="p">,</span> <span class="n">ai_response</span><span class="p">,</span> <span class="n">speech_audio</span>
    
    <span class="k">def</span> <span class="nf">get_medical_response</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
        <span class="s">"""Get response from medical AI system"""</span>
        <span class="c1"># Integration with your existing RAG system
</span>        <span class="n">medical_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"""
        You are a medical assistant helping healthcare professionals.
        
        Query: </span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s">
        
        Provide a concise, accurate response suitable for voice interaction.
        Keep responses under 100 words for better speech synthesis.
        """</span>
        
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">openai_client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s">"gpt-4"</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"system"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="n">medical_prompt</span><span class="p">},</span>
                <span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">conversation_history</span><span class="p">[</span><span class="o">-</span><span class="mi">6</span><span class="p">:]</span>  <span class="c1"># Last 3 exchanges for context
</span>            <span class="p">],</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">response</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span>

<span class="c1"># Streamlit App
</span><span class="n">st</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"üé§ Voice Medical Assistant"</span><span class="p">)</span>
<span class="n">st</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"Click the microphone to record your medical question"</span><span class="p">)</span>

<span class="c1"># Initialize assistant
</span><span class="k">if</span> <span class="s">'medical_assistant'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">st</span><span class="p">.</span><span class="n">session_state</span><span class="p">:</span>
    <span class="n">st</span><span class="p">.</span><span class="n">session_state</span><span class="p">.</span><span class="n">medical_assistant</span> <span class="o">=</span> <span class="n">VoiceMedicalAssistant</span><span class="p">()</span>

<span class="c1"># Audio recorder component
</span><span class="n">audio_bytes</span> <span class="o">=</span> <span class="n">audio_recorder</span><span class="p">(</span>
    <span class="n">text</span><span class="o">=</span><span class="s">"Click to record"</span><span class="p">,</span>
    <span class="n">recording_color</span><span class="o">=</span><span class="s">"#e8b62c"</span><span class="p">,</span>
    <span class="n">neutral_color</span><span class="o">=</span><span class="s">"#6aa36f"</span><span class="p">,</span>
    <span class="n">icon_name</span><span class="o">=</span><span class="s">"microphone"</span><span class="p">,</span>
    <span class="n">icon_size</span><span class="o">=</span><span class="s">"2x"</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">if</span> <span class="n">audio_bytes</span><span class="p">:</span>
    <span class="n">st</span><span class="p">.</span><span class="n">audio</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">"audio/wav"</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">st</span><span class="p">.</span><span class="n">spinner</span><span class="p">(</span><span class="s">"Processing your voice query..."</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">st</span><span class="p">.</span><span class="n">session_state</span><span class="p">.</span><span class="n">medical_assistant</span><span class="p">.</span><span class="n">process_voice_query</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>  <span class="c1"># If transcription successful
</span>            <span class="n">transcription</span><span class="p">,</span> <span class="n">ai_response</span><span class="p">,</span> <span class="n">speech_audio</span> <span class="o">=</span> <span class="n">result</span>
            
            <span class="c1"># Display conversation
</span>            <span class="n">st</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"**You said:**"</span><span class="p">,</span> <span class="n">transcription</span><span class="p">)</span>
            <span class="n">st</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"**Medical Assistant:**"</span><span class="p">,</span> <span class="n">ai_response</span><span class="p">)</span>
            
            <span class="c1"># Play AI response
</span>            <span class="k">if</span> <span class="n">speech_audio</span><span class="p">:</span>
                <span class="n">st</span><span class="p">.</span><span class="n">audio</span><span class="p">(</span><span class="n">speech_audio</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">"audio/mpeg"</span><span class="p">)</span>
            
            <span class="c1"># Show conversation history
</span>            <span class="k">with</span> <span class="n">st</span><span class="p">.</span><span class="n">expander</span><span class="p">(</span><span class="s">"Conversation History"</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">st</span><span class="p">.</span><span class="n">session_state</span><span class="p">.</span><span class="n">medical_assistant</span><span class="p">.</span><span class="n">conversation_history</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]:</span>
                    <span class="n">role</span> <span class="o">=</span> <span class="s">"üßë‚Äç‚öïÔ∏è You"</span> <span class="k">if</span> <span class="n">msg</span><span class="p">[</span><span class="s">"role"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"user"</span> <span class="k">else</span> <span class="s">"ü§ñ Assistant"</span>
                    <span class="n">st</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"**</span><span class="si">{</span><span class="n">role</span><span class="si">}</span><span class="s">:** </span><span class="si">{</span><span class="n">msg</span><span class="p">[</span><span class="s">'content'</span><span class="p">]</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="advanced-features">Advanced Features</h2>

<h3 id="1-continuous-conversation-mode">1. Continuous Conversation Mode</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ContinuousVoiceChat</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">is_listening</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conversation_active</span> <span class="o">=</span> <span class="bp">False</span>
        
    <span class="k">def</span> <span class="nf">start_continuous_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Enable hands-free conversation"""</span>
        <span class="n">st</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"üé§ Continuous mode active - say 'Hey Assistant' to start"</span><span class="p">)</span>
        
        <span class="c1"># Voice activation detection
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">detect_wake_word</span><span class="p">(</span><span class="s">"hey assistant"</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">conversation_active</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="n">st</span><span class="p">.</span><span class="n">success</span><span class="p">(</span><span class="s">"Voice assistant activated!"</span><span class="p">)</span>
            
            <span class="c1"># Continue conversation until "goodbye"
</span>            <span class="k">while</span> <span class="bp">self</span><span class="p">.</span><span class="n">conversation_active</span><span class="p">:</span>
                <span class="n">audio</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">listen_for_speech</span><span class="p">()</span>
                <span class="k">if</span> <span class="s">"goodbye"</span> <span class="ow">in</span> <span class="n">audio</span><span class="p">.</span><span class="n">lower</span><span class="p">():</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">conversation_active</span> <span class="o">=</span> <span class="bp">False</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">speak</span><span class="p">(</span><span class="s">"Goodbye! Have a great day."</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">process_medical_query</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">speak</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="2-multi-language-support">2. Multi-Language Support</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultilingualVoiceAssistant</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">supported_languages</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'en'</span><span class="p">:</span> <span class="s">'English'</span><span class="p">,</span>
            <span class="s">'es'</span><span class="p">:</span> <span class="s">'Spanish'</span><span class="p">,</span> 
            <span class="s">'hi'</span><span class="p">:</span> <span class="s">'Hindi'</span><span class="p">,</span>
            <span class="s">'ta'</span><span class="p">:</span> <span class="s">'Tamil'</span>
        <span class="p">}</span>
        
    <span class="k">def</span> <span class="nf">detect_language</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_bytes</span><span class="p">):</span>
        <span class="s">"""Detect spoken language"""</span>
        <span class="c1"># Use Whisper's language detection
</span>        <span class="n">result</span> <span class="o">=</span> <span class="n">openai</span><span class="p">.</span><span class="n">Audio</span><span class="p">.</span><span class="n">transcribe</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s">"whisper-1"</span><span class="p">,</span>
            <span class="nb">file</span><span class="o">=</span><span class="n">audio_bytes</span><span class="p">,</span>
            <span class="n">response_format</span><span class="o">=</span><span class="s">"verbose_json"</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span><span class="p">.</span><span class="n">language</span>
    
    <span class="k">def</span> <span class="nf">transcribe_multilingual</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_bytes</span><span class="p">):</span>
        <span class="s">"""Transcribe in detected language"""</span>
        <span class="n">language</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">detect_language</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">)</span>
        
        <span class="n">transcript</span> <span class="o">=</span> <span class="n">openai</span><span class="p">.</span><span class="n">Audio</span><span class="p">.</span><span class="n">transcribe</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s">"whisper-1"</span><span class="p">,</span>
            <span class="nb">file</span><span class="o">=</span><span class="n">audio_bytes</span><span class="p">,</span>
            <span class="n">language</span><span class="o">=</span><span class="n">language</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">transcript</span><span class="p">,</span> <span class="n">language</span>
    
    <span class="k">def</span> <span class="nf">respond_in_language</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">target_language</span><span class="p">):</span>
        <span class="s">"""Generate response in user's language"""</span>
        <span class="k">if</span> <span class="n">target_language</span> <span class="o">!=</span> <span class="s">'en'</span><span class="p">:</span>
            <span class="c1"># Translate to English for processing
</span>            <span class="n">english_text</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">translate_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">target_language</span><span class="p">,</span> <span class="s">'en'</span><span class="p">)</span>
            <span class="n">english_response</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_medical_response</span><span class="p">(</span><span class="n">english_text</span><span class="p">)</span>
            <span class="c1"># Translate response back
</span>            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">translate_text</span><span class="p">(</span><span class="n">english_response</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="n">target_language</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_medical_response</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="n">response</span>
</code></pre></div></div>

<h3 id="3-integration-with-multi-agent-systems">3. Integration with Multi-Agent Systems</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">VoiceEnabledCrewAI</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">voice_interface</span> <span class="o">=</span> <span class="n">ProductionVoiceInterface</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">medical_crew</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">setup_medical_crew</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">voice_crew_interaction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_bytes</span><span class="p">):</span>
        <span class="s">"""Voice interaction with CrewAI system"""</span>
        <span class="c1"># Transcribe user query
</span>        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">voice_interface</span><span class="p">.</span><span class="n">transcribe_audio</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">)</span>
        
        <span class="c1"># Determine which crew to use based on query
</span>        <span class="n">crew_type</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">classify_query_type</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">crew_type</span> <span class="o">==</span> <span class="s">"diagnostic"</span><span class="p">:</span>
            <span class="n">crew</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">diagnostic_crew</span>
        <span class="k">elif</span> <span class="n">crew_type</span> <span class="o">==</span> <span class="s">"treatment"</span><span class="p">:</span>
            <span class="n">crew</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">treatment_crew</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">crew</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">general_medical_crew</span>
        
        <span class="c1"># Execute crew with voice-optimized prompts
</span>        <span class="n">result</span> <span class="o">=</span> <span class="n">crew</span><span class="p">.</span><span class="n">kickoff</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">{</span>
            <span class="s">"query"</span><span class="p">:</span> <span class="n">query</span><span class="p">,</span>
            <span class="s">"response_format"</span><span class="p">:</span> <span class="s">"voice_friendly"</span>  <span class="c1"># Shorter, clearer responses
</span>        <span class="p">})</span>
        
        <span class="c1"># Generate speech response
</span>        <span class="n">speech_audio</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">voice_interface</span><span class="p">.</span><span class="n">generate_speech</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">query</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">speech_audio</span>
    
    <span class="k">def</span> <span class="nf">classify_query_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
        <span class="s">"""Classify query to route to appropriate crew"""</span>
        <span class="n">classification_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"""
        Classify this medical query into one category:
        - diagnostic: Questions about symptoms, diagnosis, or assessment
        - treatment: Questions about medications, procedures, or interventions  
        - general: General medical information or guidelines
        
        Query: </span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s">
        
        Return only the category name.
        """</span>
        
        <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="p">.</span><span class="n">ChatCompletion</span><span class="p">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s">"gpt-3.5-turbo"</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"user"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="n">classification_prompt</span><span class="p">}],</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">10</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">response</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="n">strip</span><span class="p">().</span><span class="n">lower</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="real-world-deployment">Real-World Deployment</h2>

<h3 id="hospital-integration">Hospital Integration</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">HospitalVoiceSystem</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">voice_assistant</span> <span class="o">=</span> <span class="n">VoiceMedicalAssistant</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">user_authentication</span> <span class="o">=</span> <span class="n">UserAuth</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">audit_logger</span> <span class="o">=</span> <span class="n">AuditLogger</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">secure_voice_interaction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_bytes</span><span class="p">,</span> <span class="n">user_id</span><span class="p">):</span>
        <span class="s">"""HIPAA-compliant voice interaction"""</span>
        <span class="c1"># Authenticate user
</span>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">user_authentication</span><span class="p">.</span><span class="n">verify_user</span><span class="p">(</span><span class="n">user_id</span><span class="p">):</span>
            <span class="k">return</span> <span class="s">"Authentication required"</span>
        
        <span class="c1"># Process voice query
</span>        <span class="n">transcription</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">speech_audio</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">voice_assistant</span><span class="p">.</span><span class="n">process_voice_query</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">)</span>
        
        <span class="c1"># Log interaction for compliance
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">audit_logger</span><span class="p">.</span><span class="n">log_interaction</span><span class="p">(</span>
            <span class="n">user_id</span><span class="o">=</span><span class="n">user_id</span><span class="p">,</span>
            <span class="n">query</span><span class="o">=</span><span class="n">transcription</span><span class="p">,</span>
            <span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">,</span>
            <span class="n">timestamp</span><span class="o">=</span><span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">()</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">transcription</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">speech_audio</span>
    
    <span class="k">def</span> <span class="nf">emergency_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_bytes</span><span class="p">):</span>
        <span class="s">"""Fast response for emergency situations"""</span>
        <span class="c1"># Skip some processing for speed
</span>        <span class="n">transcription</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">voice_assistant</span><span class="p">.</span><span class="n">voice_interface</span><span class="p">.</span><span class="n">transcribe_audio</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">)</span>
        
        <span class="c1"># Emergency-specific prompts
</span>        <span class="n">emergency_response</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_emergency_response</span><span class="p">(</span><span class="n">transcription</span><span class="p">)</span>
        
        <span class="c1"># Priority speech generation
</span>        <span class="n">speech_audio</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">voice_assistant</span><span class="p">.</span><span class="n">voice_interface</span><span class="p">.</span><span class="n">generate_speech</span><span class="p">(</span><span class="n">emergency_response</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">transcription</span><span class="p">,</span> <span class="n">emergency_response</span><span class="p">,</span> <span class="n">speech_audio</span>
</code></pre></div></div>

<h3 id="mobile-app-integration">Mobile App Integration</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Streamlit mobile-optimized interface
</span><span class="n">st</span><span class="p">.</span><span class="n">set_page_config</span><span class="p">(</span>
    <span class="n">page_title</span><span class="o">=</span><span class="s">"Voice Medical Assistant"</span><span class="p">,</span>
    <span class="n">page_icon</span><span class="o">=</span><span class="s">"üé§"</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="s">"wide"</span><span class="p">,</span>
    <span class="n">initial_sidebar_state</span><span class="o">=</span><span class="s">"collapsed"</span>
<span class="p">)</span>

<span class="c1"># Mobile-friendly CSS
</span><span class="n">st</span><span class="p">.</span><span class="n">markdown</span><span class="p">(</span><span class="s">"""
&lt;style&gt;
.main-header {
    font-size: 2rem;
    text-align: center;
    margin-bottom: 2rem;
}

.record-button {
    display: flex;
    justify-content: center;
    margin: 2rem 0;
}

.response-card {
    background: #f0f2f6;
    padding: 1rem;
    border-radius: 10px;
    margin: 1rem 0;
}
&lt;/style&gt;
"""</span><span class="p">,</span> <span class="n">unsafe_allow_html</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">st</span><span class="p">.</span><span class="n">markdown</span><span class="p">(</span><span class="s">'&lt;h1 class="main-header"&gt;üé§ Voice Medical Assistant&lt;/h1&gt;'</span><span class="p">,</span> <span class="n">unsafe_allow_html</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Large, touch-friendly record button
</span><span class="n">col1</span><span class="p">,</span> <span class="n">col2</span><span class="p">,</span> <span class="n">col3</span> <span class="o">=</span> <span class="n">st</span><span class="p">.</span><span class="n">columns</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="k">with</span> <span class="n">col2</span><span class="p">:</span>
    <span class="n">audio_bytes</span> <span class="o">=</span> <span class="n">audio_recorder</span><span class="p">(</span>
        <span class="n">text</span><span class="o">=</span><span class="s">"Tap to Record"</span><span class="p">,</span>
        <span class="n">recording_color</span><span class="o">=</span><span class="s">"#ff6b6b"</span><span class="p">,</span>
        <span class="n">neutral_color</span><span class="o">=</span><span class="s">"#4ecdc4"</span><span class="p">,</span>
        <span class="n">icon_size</span><span class="o">=</span><span class="s">"3x"</span>
    <span class="p">)</span>
</code></pre></div></div>

<h2 id="performance-optimization">Performance Optimization</h2>

<h3 id="caching-and-speed-improvements">Caching and Speed Improvements</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">@</span><span class="n">st</span><span class="p">.</span><span class="n">cache_resource</span>
<span class="k">def</span> <span class="nf">load_voice_models</span><span class="p">():</span>
    <span class="s">"""Cache expensive model loading"""</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s">'whisper'</span><span class="p">:</span> <span class="n">whisper</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">"base"</span><span class="p">),</span>
        <span class="s">'medical_rag'</span><span class="p">:</span> <span class="n">load_medical_rag_system</span><span class="p">(),</span>
        <span class="s">'crew_ai'</span><span class="p">:</span> <span class="n">setup_medical_crew</span><span class="p">()</span>
    <span class="p">}</span>

<span class="o">@</span><span class="n">st</span><span class="p">.</span><span class="n">cache_data</span><span class="p">(</span><span class="n">ttl</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>  <span class="c1"># Cache for 5 minutes
</span><span class="k">def</span> <span class="nf">get_cached_medical_response</span><span class="p">(</span><span class="n">query_hash</span><span class="p">):</span>
    <span class="s">"""Cache common medical responses"""</span>
    <span class="k">return</span> <span class="n">medical_response_cache</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">query_hash</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">OptimizedVoiceInterface</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">load_voice_models</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">response_cache</span> <span class="o">=</span> <span class="p">{}</span>
        
    <span class="k">def</span> <span class="nf">fast_transcription</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_bytes</span><span class="p">):</span>
        <span class="s">"""Optimized transcription with caching"""</span>
        <span class="n">audio_hash</span> <span class="o">=</span> <span class="n">hashlib</span><span class="p">.</span><span class="n">md5</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">).</span><span class="n">hexdigest</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">audio_hash</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">transcription_cache</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">transcription_cache</span><span class="p">[</span><span class="n">audio_hash</span><span class="p">]</span>
        
        <span class="c1"># Use faster Whisper model for real-time
</span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">models</span><span class="p">[</span><span class="s">'whisper'</span><span class="p">].</span><span class="n">transcribe</span><span class="p">(</span>
            <span class="n">audio_bytes</span><span class="p">,</span>
            <span class="n">fp16</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>  <span class="c1"># Faster on CPU
</span>            <span class="n">language</span><span class="o">=</span><span class="s">'en'</span>  <span class="c1"># Skip language detection
</span>        <span class="p">)</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">transcription_cache</span><span class="p">[</span><span class="n">audio_hash</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s">'text'</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">result</span><span class="p">[</span><span class="s">'text'</span><span class="p">]</span>
</code></pre></div></div>

<h2 id="results-and-user-feedback">Results and User Feedback</h2>

<p>After deploying voice-enabled AI in our hospital:</p>

<p><strong>Usage Statistics</strong>:</p>
<ul>
  <li><strong>Daily voice interactions</strong>: 150+ per day</li>
  <li><strong>Average response time</strong>: 3-5 seconds</li>
  <li><strong>Transcription accuracy</strong>: 92% in clinical settings</li>
  <li><strong>User satisfaction</strong>: 88% prefer voice over typing</li>
</ul>

<p><strong>User Feedback</strong>:</p>
<ul>
  <li>‚úÖ ‚ÄúMuch faster during patient examinations‚Äù</li>
  <li>‚úÖ ‚ÄúHands-free operation is game-changing‚Äù</li>
  <li>‚úÖ ‚ÄúNatural conversation flow‚Äù</li>
  <li>‚ùå ‚ÄúSometimes struggles with medical terminology‚Äù</li>
  <li>‚ùå ‚ÄúBackground noise can interfere‚Äù</li>
</ul>

<h2 id="challenges-and-solutions">Challenges and Solutions</h2>

<h3 id="1-medical-terminology-accuracy">1. Medical Terminology Accuracy</h3>
<p><strong>Problem</strong>: Whisper sometimes misunderstands medical terms
<strong>Solution</strong>: Custom vocabulary and post-processing correction</p>

<h3 id="2-privacy-concerns">2. Privacy Concerns</h3>
<p><strong>Problem</strong>: Voice data contains sensitive information
<strong>Solution</strong>: Local processing where possible, encrypted transmission</p>

<h3 id="3-noise-in-clinical-settings">3. Noise in Clinical Settings</h3>
<p><strong>Problem</strong>: Hospital environments are noisy
<strong>Solution</strong>: Noise cancellation and directional microphones</p>

<h2 id="whats-next">What‚Äôs Next</h2>

<p>I‚Äôm exploring:</p>
<ol>
  <li><strong>Real-time conversation</strong>: Streaming audio processing</li>
  <li><strong>Emotion detection</strong>: Understanding urgency in voice</li>
  <li><strong>Multi-speaker support</strong>: Handling multiple people in conversations</li>
  <li><strong>Integration with wearables</strong>: Voice AI on smartwatches</li>
</ol>

<p>Voice AI has transformed how healthcare professionals interact with our AI systems. The ability to have natural conversations while maintaining focus on patient care is genuinely revolutionary.</p>

<hr />

<p><em>Next post: I‚Äôm working on AI model selection strategies - when to use GPT vs Claude vs open-source models for different business scenarios.</em></p>

  </div>

  <!-- Social Share Buttons -->
  <div class="share-buttons">
    <h4>Share this post:</h4>
    <a href="https://twitter.com/intent/tweet?text=Voice%20AI%20Integration:%20Adding%20Speech%20to%20My%20AI%20Applications%20with%20Streamlit&url=http://localhost:4009/2025/06/15/voice-ai-integration-streamlit/" 
       class="share-button" target="_blank" rel="noopener" aria-label="Share on Twitter">
      üê¶ Twitter
    </a>
    <a href="https://www.linkedin.com/sharing/share-offsite/?url=http://localhost:4009/2025/06/15/voice-ai-integration-streamlit/" 
       class="share-button" target="_blank" rel="noopener" aria-label="Share on LinkedIn">
      üíº LinkedIn
    </a>
    <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4009/2025/06/15/voice-ai-integration-streamlit/" 
       class="share-button" target="_blank" rel="noopener" aria-label="Share on Facebook">
      üìò Facebook
    </a>
    <button class="share-button" onclick="copyToClipboard('http://localhost:4009/2025/06/15/voice-ai-integration-streamlit/')" aria-label="Copy link">
      üîó Copy Link
    </button>
  </div>

  <!-- AI-Powered Recommendations -->
  <div class="recommendations">
    <h3>Recommended for you</h3>
    <div class="recommended-posts">
      
      
      
      
        <div class="post-card">
          <div class="post-image">üí°</div>
          <h4><a href="/2025/08/20/ai-model-selection-strategies/">AI Model Selection: When to Use GPT vs Claude vs Open Source Models</a></h4>
          <div class="post-meta">August 20, 2025</div>
          <div class="post-excerpt">After using different AI models for 8 months, I've learned when each one shines. Here's my practical guide to choosing...</div>
        </div>
      
        <div class="post-card">
          <div class="post-image">üí°</div>
          <h4><a href="/2025/04/10/building-multi-agent-systems-crewai/">Building Multi-Agent Systems with CrewAI: Beyond Single AI Assistants</a></h4>
          <div class="post-meta">April 10, 2025</div>
          <div class="post-excerpt">I built my first multi-agent system using CrewAI. Here's what I learned about orchestrating multiple AI agents to solve complex...</div>
        </div>
      
        <div class="post-card">
          <div class="post-image">üí°</div>
          <h4><a href="/2025/02/20/chain-of-thought-prompting-business-logic/">Chain-of-Thought Prompting: Improving AI Reasoning in Business Applications</a></h4>
          <div class="post-meta">February 20, 2025</div>
          <div class="post-excerpt">Can we get LLMs to reason through complex business rules reliably? My experiments with chain-of-thought prompting for healthcare protocols.</div>
        </div>
      
        <div class="post-card">
          <div class="post-image">üí°</div>
          <h4><a href="/2025/01/15/advanced-prompt-engineering-techniques/">Advanced Prompt Engineering: Techniques I've Learned from 6 Months with LLMs</a></h4>
          <div class="post-meta">January 15, 2025</div>
          <div class="post-excerpt">After 6 months of working with LLMs daily, I've discovered prompt engineering is both an art and a science. Here...</div>
        </div>
      
        <div class="post-card">
          <div class="post-image">üí°</div>
          <h4><a href="/2024/12/15/agentic-ai-customer-service-automation/">Building an Agentic AI Customer Service System: A Complete Case Study</a></h4>
          <div class="post-meta">December 15, 2024</div>
          <div class="post-excerpt">How I built a multi-agent customer service system that reduced response time by 85% and improved satisfaction scores by 40%...</div>
        </div>
      
        <div class="post-card">
          <div class="post-image">üí°</div>
          <h4><a href="/2024/10/20/getting-started-langchain-rag/">Building RAG Systems: My Journey with LangChain</a></h4>
          <div class="post-meta">October 20, 2024</div>
          <div class="post-excerpt">After months of hearing about RAG and LangChain, I finally built my first retrieval-augmented generation system. Here's what I learned....</div>
        </div>
      
        <div class="post-card">
          <div class="post-image">üí°</div>
          <h4><a href="/2024/09/10/ai-powered-data-quality-monitoring/">AI-Powered Data Quality Monitoring: The Future of Data Reliability</a></h4>
          <div class="post-meta">September 10, 2024</div>
          <div class="post-excerpt">Discover how artificial intelligence is revolutionizing data quality monitoring with automated anomaly detection, intelligent alerting, and predictive data health insights....</div>
        </div>
      
        <div class="post-card">
          <div class="post-image">üí°</div>
          <h4><a href="/2024/06/20/advanced-kafka-streaming-patterns/">Advanced Kafka Streaming Patterns for Real-Time Analytics</a></h4>
          <div class="post-meta">June 20, 2024</div>
          <div class="post-excerpt">Explore advanced Apache Kafka streaming patterns including exactly-once processing, windowing operations, and complex event processing for building robust real-time analytics...</div>
        </div>
      
        <div class="post-card">
          <div class="post-image">üí°</div>
          <h4><a href="/2024/03/15/building-enterprise-ai-customer-support-system/">Building an Enterprise AI Customer Support System: From Concept to $485K Annual Savings</a></h4>
          <div class="post-meta">March 15, 2024</div>
          <div class="post-excerpt">How I built a Fortune 500-grade multi-agent customer support system using 100% free technologies, achieving 85% faster response times and...</div>
        </div>
      
        <div class="post-card">
          <div class="post-image">üí°</div>
          <h4><a href="/2023/04/20/mlops-deployment-strategies/">MLOps: Machine Learning Deployment Strategies</a></h4>
          <div class="post-meta">April 20, 2023</div>
          <div class="post-excerpt">MLOps: Machine Learning Deployment Strategies

</div>
        </div>
      
    </div>
  </div>

  <!-- Comments Section -->
  
</article>

<script>
  function copyToClipboard(text) {
    navigator.clipboard.writeText(text).then(() => {
      alert('Link copied to clipboard!');
    });
  }
</script>
    </main>
    
    <!-- WhatsApp Chat Widget -->
    <div class="whatsapp-chat" id="whatsapp-chat">
        <div class="chat-bubble">
            <svg viewBox="0 0 24 24" fill="white">
                <path d="M17.472 14.382c-.297-.149-1.758-.867-2.03-.967-.273-.099-.471-.148-.67.15-.197.297-.767.966-.94 1.164-.173.199-.347.223-.644.075-.297-.15-1.255-.463-2.39-1.475-.883-.788-1.48-1.761-1.653-2.059-.173-.297-.018-.458.13-.606.134-.133.298-.347.446-.52.149-.174.198-.298.298-.497.099-.198.05-.371-.025-.52-.075-.149-.669-1.612-.916-2.207-.242-.579-.487-.5-.669-.51-.173-.008-.371-.01-.57-.01-.198 0-.52.074-.792.372-.272.297-1.04 1.016-1.04 2.479 0 1.462 1.065 2.875 1.213 3.074.149.198 2.096 3.2 5.077 4.487.709.306 1.262.489 1.694.625.712.227 1.36.195 1.871.118.571-.085 1.758-.719 2.006-1.413.248-.694.248-1.289.173-1.413-.074-.124-.272-.198-.57-.347m-5.421 7.403h-.004a9.87 9.87 0 01-5.031-1.378l-.361-.214-3.741.982.998-3.648-.235-.374a9.86 9.86 0 01-1.51-5.26c.001-5.45 4.436-9.884 9.888-9.884 2.64 0 5.122 1.03 6.988 2.898a9.825 9.825 0 012.893 6.994c-.003 5.45-4.437 9.884-9.885 9.884m8.413-18.297A11.815 11.815 0 0012.05 0C5.495 0 .16 5.335.157 11.892c0 2.096.547 4.142 1.588 5.945L.057 24l6.305-1.654a11.882 11.882 0 005.683 1.448h.005c6.554 0 11.89-5.335 11.893-11.893A11.821 11.821 0 0020.885 3.488"/>
            </svg>
        </div>
        <div class="chat-tooltip">Chat with me on WhatsApp!</div>
    </div>

    <footer role="contentinfo">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h4>Connect</h4>
                    <div class="social-links">
                        <a href="https://github.com/niranjanagaram" aria-label="GitHub Profile">GitHub</a>
                        <a href="https://linkedin.com/in/niranjan-agaram" aria-label="LinkedIn Profile">LinkedIn</a>
                        <a href="mailto:niranjan@example.com" aria-label="Email Contact">Email</a>
                    </div>
                </div>
                <div class="footer-section">
                    <h4>Subscribe</h4>
                    <a href="/feed.xml" aria-label="RSS Feed">RSS Feed</a>
                </div>
            </div>
            <p>&copy; 2025 Niranjan's AI Insights. All rights reserved.</p>
        </div>
    </footer>
    
    <!-- Service Worker -->
    <script>
        if ('serviceWorker' in navigator) {
            navigator.serviceWorker.register('/sw.js');
        }
        
        // Modern Theme Toggle
        const themeToggle = document.getElementById('theme-toggle');
        const currentTheme = localStorage.getItem('theme') || 'dark';
        
        document.documentElement.setAttribute('data-theme', currentTheme);
        
        themeToggle.addEventListener('click', () => {
            const theme = document.documentElement.getAttribute('data-theme');
            const newTheme = theme === 'dark' ? 'light' : 'dark';
            document.documentElement.setAttribute('data-theme', newTheme);
            localStorage.setItem('theme', newTheme);
        });
        
        // Reading Progress
        window.addEventListener('scroll', () => {
            const progress = document.getElementById('reading-progress');
            const scrolled = (window.scrollY / (document.body.scrollHeight - window.innerHeight)) * 100;
            progress.style.width = scrolled + '%';
        });
        

    </script>
</body>
</html>